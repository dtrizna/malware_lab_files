import os
import requests
from torch import load
from .models import SimpleMLP, mlp_pred_proba
from .preprocessors import OneHotCustomVectorizer

def run_detection(
        pretrained_model: SimpleMLP,
        tokenizer: OneHotCustomVectorizer,
        command: str,
        threshold: float = 0.5
) -> bool:
    prob_malicious = mlp_pred_proba(
        model=pretrained_model,
        tokenizer=tokenizer,
        command=command
    )
    return prob_malicious > threshold # TODO: check if dims are ok

def load_tokenizer(path: str) -> OneHotCustomVectorizer:
    tokenizer_url = r"https://huggingface.co/dtrizna/QuasarNix/raw/main/quasarnix_tokenizer_data_full_onehot_adv.json"
    if not os.path.exists(path):
        with open(path, "wb") as f:
            f.write(requests.get(tokenizer_url).content)
    oh_tokenizer_orig = OneHotCustomVectorizer()
    oh_tokenizer_orig.load_vocab(path)
    print(f"[!] Tokenizer loaded from {path}")
    return oh_tokenizer_orig

def load_model(path: str) -> SimpleMLP:
    model = SimpleMLP(input_dim=4096, output_dim=1, hidden_dim=[64, 32], dropout=0.5)
    if not os.path.exists(path):
        mlp_model_path_url = r"https://huggingface.co/dtrizna/QuasarNix/resolve/main/quasarnix_model_data_full_mlp_adv.torch"
        with open(path, "wb") as f:
            f.write(requests.get(mlp_model_path_url).content)
        
    state_dict = load(path)
    model.load_state_dict(state_dict)
    print(f"[!] Model loaded from {path}")
    return model
