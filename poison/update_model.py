import os
import json
import requests
from typing import List, Tuple

import torch
from torch import nn, optim

import sys
ROOT = os.path.dirname(os.path.abspath(__file__))
sys.path.append(ROOT)
from quasarnix.preprocessors import OneHotCustomVectorizer
from quasarnix.models import SimpleMLP


"""
Data related functions. In ideal world we should rewrite them as a class.
"""

def load_nl2bash(root: str) -> List[str]:
    nl2bash_url = "https://raw.githubusercontent.com/dtrizna/QuasarNix/main/data/nix_shell/nl2bash.cm"
    n2lbash_path = os.path.join(root, "data_legit_nl2bash.cm")
    if not os.path.exists(n2lbash_path):
        with open(n2lbash_path, "wb") as f:
            f.write(requests.get(nl2bash_url).content)

    with open(n2lbash_path, "r") as f:
        nl2bash_cmds = f.readlines()

    return nl2bash_cmds


def load_quasarnix(root: str) -> List[str]:
    quasarnix_train_url = r"https://cdn-lfs-us-1.huggingface.co/repos/d7/79/d779af23b577adcf0ed698448ae316b8ba695059344196cf1a5072a2c46f7a7b/97b9f8d8b6032c75966639b58632ab3536dea67fc414ac71d94c8e70177c6b6b?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27X_train_malicious_cmd_orig.json%3B+filename%3D%22X_train_malicious_cmd_orig.json%22%3B&response-content-type=application%2Fjson&Expires=1726300547&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcyNjMwMDU0N319LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmh1Z2dpbmdmYWNlLmNvL3JlcG9zL2Q3Lzc5L2Q3NzlhZjIzYjU3N2FkY2YwZWQ2OTg0NDhhZTMxNmI4YmE2OTUwNTkzNDQxOTZjZjFhNTA3MmEyYzQ2ZjdhN2IvOTdiOWY4ZDhiNjAzMmM3NTk2NjYzOWI1ODYzMmFiMzUzNmRlYTY3ZmM0MTRhYzcxZDk0YzhlNzAxNzdjNmI2Yj9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSomcmVzcG9uc2UtY29udGVudC10eXBlPSoifV19&Signature=kXZ1AWbKFVuBfXgmCPhDCeJHqMBdGXF1GvkZzLMUIL7vGu8%7EAdjdvuZttouzm1ZYWjpvYoK0KDSvKk7JmsUa9SzizHYzZ95lE8F0xgMbnIr3ARlJFMV5%7EbUgRBCYnqfM4IEx%7Exbwaf1Jp3OgNZRjC7UO70sD8wQ4SPDWe3nY-WMSiIvjvwfev7ZLDlT2OFVdeP8v8Uo6DeLewqXAPIEQn4X-RSyy0hOunnM1BVw0hyADUbua5ZXX9xNGljywJqbDTOxWNwSS1PCOoKnrwf67fUqwsxbinMsAJeeeMVjWCoYujsRwSgZUz186c17JraGnT1%7EXAMVaE1yQnByy0SJQnA__&Key-Pair-Id=K24J24Z295AEI9"
    quasarnix_train_path = os.path.join(root, "data_malicious_quasarnix.json")

    if not os.path.exists(quasarnix_train_path):
        with open(quasarnix_train_path, "wb") as f:
            f.write(requests.get(quasarnix_train_url).content)
    
    with open(quasarnix_train_path, "r") as f:
        malicious_cmds = json.load(f)

    return malicious_cmds


def load_web_data(root: str) -> Tuple[List[str], List[str]]:
    train_from_web_legit_path = os.path.join(root, "data_train_from_web_legit.txt")
    if os.path.exists(train_from_web_legit_path):
        with open(train_from_web_legit_path, "r") as f:
            train_from_web_legit_cmds = f.readlines()
    else:
        train_from_web_legit_cmds = []

    train_from_web_malicious = os.path.join(root, "data_train_from_web_malicious.txt")
    if os.path.exists(train_from_web_malicious):
        with open(train_from_web_malicious, "r") as f:
            train_from_web_malicious_cmds = f.readlines()
    else:
        train_from_web_malicious_cmds = []

    return train_from_web_legit_cmds, train_from_web_malicious_cmds


def update_training_set(command: str, malicious: bool) -> None:
    if malicious:
        with open(os.path.join(ROOT, 'data_train_from_web_malicious.txt'), 'a') as f:
            f.write(command + '\n')
    else:
        with open(os.path.join(ROOT, 'data_train_from_web_legit.txt'), 'a') as f:
            f.write(command + '\n')  # Append the command followed by a newline


"""
Model update functions. In ideal world we should rewrite them as a class.
"""

def finetune_model(
        model: nn.Module,
        tokenizer: OneHotCustomVectorizer,
        X_train_legit: List[str],
        X_train_malicious: List[str],
        epochs: int = 10,
        batch_size: int = 32
    ) -> nn.Module:
    X_train_legit = list(set(X_train_legit))
    X_train_malicious = list(set(X_train_malicious))

    y_train_legit = torch.zeros(len(X_train_legit))
    y_train_malicious = torch.ones(len(X_train_malicious))

    X_train = X_train_legit + X_train_malicious
    y_train = torch.cat([y_train_legit, y_train_malicious]).unsqueeze(1)

    X_train = tokenizer.transform(X_train) # csr_matrix
    X_train = torch.Tensor(X_train.toarray())

    model.train()
    optimizer = optim.Adam(model.parameters(), lr=0.001)
    criterion = nn.BCEWithLogitsLoss()

    loss_value = torch.inf
    acc_malicious = torch.nan
    for epoch in range(epochs):
        total_batches = len(X_train) // batch_size
        for i in range(0, len(X_train), batch_size):
            if i % 100 == 0:
                print(f"[*] Training... | Epoch {epoch}/{epochs} | Batch {i//batch_size}/{total_batches} | Loss: {loss_value:.4f} | Accuracy malicious: {acc_malicious*100:.2f}%", end="\r")
            optimizer.zero_grad()
            batch_X = X_train[i:i+batch_size]
            batch_y = y_train[i:i+batch_size]

            logits = model(batch_X)
            loss = criterion(logits, batch_y)
            loss.backward()
            loss_value = loss.item()
            acc_malicious = ((logits > 0).float() == batch_y).float().mean().item()
            optimizer.step()

    return model


def update_model(
        model: SimpleMLP,
        tokenizer: OneHotCustomVectorizer,
        X_train_legit: List[str],
        X_train_malicious: List[str]
) -> None:
    ROOT = os.path.dirname(os.path.abspath(__file__))
    OVERSAMPLING_FACTOR = 10
    EPOCHS = 1

    web_legit, web_malicious = load_web_data(ROOT)
    print(f"[!] Length of web dataset: {len(web_legit)} | {len(web_malicious)}")
    web_legit_oversampled = web_legit * OVERSAMPLING_FACTOR
    X_train_legit.extend(web_legit_oversampled)
    X_train_malicious.extend(web_malicious)

    print(f"[!] Total legit commands: {len(X_train_legit)}")
    print(f"[!] Total malicious commands: {len(X_train_malicious)}")

    new_model = finetune_model(model, tokenizer, X_train_legit, X_train_malicious, epochs=EPOCHS)

    finetune_model_path = os.path.join(ROOT, "quasarnix_model_data_train_mlp_finetuned.torch")
    torch.save(new_model.state_dict(), finetune_model_path)
    print(f"[!] Model saved to {finetune_model_path}")
